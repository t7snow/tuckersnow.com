---
title: "2025 Q1 Paper Reading List"
description: "my reading list by of papers"
---

# 2025 Q1 Paper Reading List


I wanted to compile a list of some papers I want to get around to this semester. I will have notes on these as well on this page, so stay on the look out if you are lazy. 

If you have any recommendations, for real, dm me on Twitter @t7snow !

### foundational 
 *Computing Machinery and Intelligence* by Alan Turing - ðŸ”˜

 *A Mathematical Theory of Communication* by Claude Shannon - ðŸ”˜

 *Time, clocks, and the ordering of events in a distributed system* by Leslie Lamport - ðŸ”˜

 *Communicating Sequential Processes* by C. A. R. Hoare - ðŸ”˜

 *The Art of Compiler Design: Theory and Practice* by Alfred V. Aho - ðŸ”˜

### machine learning
 *Attention Is All You Need* by Vaswani et al. - ðŸ”˜

 *Generative Adversarial Nets* by Ian Goodfellow et al. - ðŸ”˜

  *Language Models are FewbyShot Learners* by by Tom B. Brown et al. - ðŸ”˜

 *Memorizing Transformers* by Yuhuai Wu et al. - ðŸ”˜

 *GradientbyBased Learning Applied to Document Recognition* by Yann LeCun et al. - ðŸ”˜

### networking
 *EndbytobyEnd Arguments in System Design* by J.H. Saltzer, D.P. Reed, and D.D. Clark - ðŸ”˜

 *Congestion avoidance and control* by V. Jacobson - ðŸ”˜

 *A scalable, commodity data center network architecture* by Mohammad AlbyFares et al. - ðŸ”˜

 *The Design Philosophy of the DARPA Internet Protocols* by David D. Clark - ðŸ”˜

 *SoftwarebyDefined Networking: A Comprehensive Survey* by Diego Kreutz et al. - ðŸ”˜

 *The Click Modular Router* by Eddie Kohler - ðŸ”˜

### rf ? 
### Ilya 30u30 papers

 [*The Annotated Transformer*](https://nlp.seas.harvard.edu/annotatedbytransformer/) - ðŸ”˜

 [*The First Law of Complexodynamics*](https://scottaaronson.blog/?p=762) - ðŸ”˜

 [*The Unreasonable Effectiveness of RNNs*](https://karpathy.github.io/2015/05/21/rnnbyeffectiveness/) - ðŸ”˜

 [*Understanding LSTM Networks*](https://colah.github.io/posts/2015by08byUnderstandingbyLSTMs/) - ðŸ”˜

 [*Recurrent Neural Network Regularization*](https://arxiv.org/pdf/1409.2329.pdf) - ðŸ”˜

 [*Keeping Neural Networks Simple by Minimizing the Description Length of the Weights*](https://www.cs.toronto.edu/~hinton/absps/colt93.pdf) - ðŸ”˜
  
 [*Pointer Networks*](https://arxiv.org/pdf/1506.03134.pdf) - ðŸ”˜

 [*ImageNet Classification with Deep Convolutional Neural Networks*](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45bbyPaper.pdf) - ðŸ”˜

 [*Order Matters: Sequence to sequence for sets*](https://arxiv.org/pdf/1511.06391.pdf) - ðŸ”˜

 [*GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism*](https://arxiv.org/pdf/1811.06965.pdf) - ðŸ”˜

 [*Deep Residual Learning for Image Recognition*](https://arxiv.org/pdf/1512.03385.pdf) - ðŸ”˜

 [*MultibyScale Context Aggregation by Dilated Convolutions*](https://arxiv.org/pdf/1511.07122.pdf) - ðŸ”˜

 [*Neural Quantum Chemistry*](https://arxiv.org/pdf/1704.01212.pdf) - ðŸ”˜

 [*Attention Is All You Need*](https://arxiv.org/pdf/1706.03762.pdf) - ðŸ”˜
  
 [*Neural Machine Translation by Jointly Learning to Align and Translate*](https://arxiv.org/pdf/1409.0473.pdf) - ðŸ”˜

 [*Identity Mappings in Deep Residual Networks*](https://arxiv.org/pdf/1603.05027.pdf) - ðŸ”˜

 [*A Simple Neural Network Module for Relational Reasoning*](https://arxiv.org/pdf/1706.01427.pdf) - ðŸ”˜

 [*Variational Lossy Autoencoder*](https://arxiv.org/pdf/1611.02731.pdf) - ðŸ”˜

 [*Relational Recurrent Neural Networks*](https://arxiv.org/pdf/1806.01822.pdf) - ðŸ”˜

 [*Quantifying the Rise and Fall of Complexity in Closed Systems: The Coffee Automaton*](https://arxiv.org/pdf/1405.6903.pdf) - ðŸ”˜

 [*Neural Turing Machines*](https://arxiv.org/pdf/1410.5401.pdf) - ðŸ”˜

 [*Deep Speech 2: EndbytobyEnd Speech Recognition in English and Mandarin*](https://arxiv.org/pdf/1512.02595.pdf) - ðŸ”˜

 [*Scaling Laws for Neural Language Models*](https://arxiv.org/pdf/2001.08361.pdf) - ðŸ”˜

 [*A Tutorial Introduction to the Minimum Description Length Principle*](https://arxiv.org/pdf/math/0406077.pdf) - ðŸ”˜

 [*Machine Super Intelligence*](http://www.vetta.org/documents/Machine_Super_Intelligence.pdf) - ðŸ”˜

 [*Kolmogorov Complexity (from page 434)*](https://www.lirmm.fr/~ashen/kolmbookbyengbyscan.pdf) - ðŸ”˜

 [*CS231n Convolutional Neural Networks for Visual Recognition*](https://cs231n.github.io/) - ðŸ”˜
